-- 7. Inductive Types
/- Intuitively, an inductive type is built up from a specified list of constructors. 
   In Lean, the syntax for specifying such a type is as follows:

     inductive foo : Sort u
     | constructor₁ : ... → foo
     | constructor₂ : ... → foo
     ...
     | constructorₙ : ... → foo

   Intuition: each constructor specifies a way of building new objects of type `foo`, 
   possibly from previously constructed values. The type `foo` consists of nothing more 
   than the objects that are constructed in this way. The first character `|` is optional. 
   Also, we could separate constructors using commas instead of bars.

   Arguments to constructors can include objects of type `foo`, subject to a certain "positivity" 
   constraint, which guarantees that elements of `foo` are built from the bottom up. 
   Roughly speaking, each `...` can be any Pi type constructed from `foo` and previously defined 
   types, in which `foo` appears, if at all, only as the "target" of the Pi type. 

   Besides inductive types, we'll see generalizations, like mutually defined inductive types and 
   *inductive families*.
-/
#print "==========================================="
#print "Section 7.1. Enumerated Types"
#print " "
-- https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html#enumerated-types

namespace Sec_7_1

  -- Every inductive type comes with 
  --   - introduction rules: show how to construct an element of the type; 
  --   - elimination rules: show how to “use” an element of the type in another construction. 
  -- Recall, intro rules for inductive types are the constructors specified in the types' defn. 
  -- Elimination rules provide for a principle of recursion on the type, which includes, 
  --   as a special case, a principle of induction as well.

  -- The simplest kind of inductive type is a finite, enumerated list of elements.
  inductive weekday : Type
  | Sunday : weekday
  | Monday : weekday
  | Tuesday : weekday
  | Wednesday : weekday
  | Thursday : weekday
  | Friday : weekday
  | Saturday : weekday
  -- Sunday, Monday, ..., Saturday are distinct elements of weekday, with no special properties.

  #check weekday.Monday
  section 
    open weekday
    #check Monday
  end
  /- The elimination principle `weekday.rec` is defined with `weekday` and its constructors. 
     `weekday.rec` is also known as a recursor; it's what makes the type "inductive" and allows 
     us to define a function on weekday by assigning values corresponding to each constructor. 
     Intuition: an inductive type is exhaustively generated by its constructors, and has no 
     elements beyond those they construct. -/

  -- We will use a variant of `weekday.rec`, `weekday.rec_on` (also generated automatically), 
  -- which takes its arguments in a more convenient order.

  -- Let's import `nat` and use `weekday.rec_on` to define a fun from weekday to natural numbers:
  namespace weekday₁
    def number_of_day (d : weekday) : ℕ := weekday.rec_on d 1 2 3 4 5 6 7
    #reduce number_of_day weekday.Sunday  -- result: 1
  end weekday₁
  /- The first (explicit) argument to `rec_on` is the element `d` being "analyzed." 
     The next seven arguments are the values corresponding to each of the seven constructors. 
     `number_of_day Sunday` evaluates to 1: the computation rule for `rec_on` sees that 
     `Sunday` is a constructor, and returns the appropriate argument. -/

  -- A more restricted variant is `cases_on`; for enumerated types, it's the same as `rec_on`, but 
  -- `cases_on` emphasizes that the definition is by cases.

  def number_of_day' (d : weekday) : ℕ := weekday.cases_on d 1 2 3 4 5 6 7

  -- It is useful to group related definitions and theorems in a single namespace. 
  -- We can put `number_of_day` in the `weekday` namespace and then use the shorter 
  -- name when we open the namespace.

  -- `rec_on` and `cases_on` are generated automatically, but are protected to avoid name clashes. 
  -- They're not provided by default when a namespace is opened, but we can declare aliases for 
  -- them with `renaming`

  namespace weekday
    @[reducible] private def cases_on := @weekday.cases_on
    def number_of_day (d : weekday) : ℕ := cases_on d 1 2 3 4 5 6 7
  end weekday

  #reduce weekday.number_of_day weekday.Monday
  -- #reduce number_of_day Sunday  -- error: unknown identifier
  -- #check @cases_on              -- error: unknown identifier
  open weekday (renaming cases_on → cases_on)  -- now we have an alias
  #reduce number_of_day Sunday
  #check @cases_on                    -- so we can use (unqualified) cases_on 

  namespace weekday   -- We can define functions from weekday to weekday:
    def next (d : weekday) : weekday :=
      weekday.cases_on d Monday Tuesday Wednesday Thursday Friday Saturday Sunday

    def previous (d : weekday) : weekday :=
      weekday.cases_on d Saturday Sunday Monday Tuesday Wednesday Thursday Friday 

    #reduce next (next Tuesday)
    #reduce next (previous Tuesday)

    example : next (previous Tuesday) = Tuesday := rfl

    theorem next_previous (d : weekday) : next (previous d) = d := 
    weekday.cases_on d 
      (show next (previous Sunday) = Sunday, from rfl)
      (show next (previous Monday) = Monday, from rfl) -- etc...
      -- `show` is just for clarity; we could just use `rfl`, as we do for the remaining cases:
      rfl rfl rfl rfl rfl

    -- With tactics, we can be even more concise
    example (d : weekday) : next (previous d) = d := by apply weekday.cases_on d; refl

    -- We could equally well have used `rec_on`:
    example (d : weekday) : next (previous d) = d := by apply weekday.rec_on d; refl

    -- Notice that, under the propositions-as-types correspondence, we can use `cases_on` to 
    -- prove theorems as well as define functions. 

  end weekday
end Sec_7_1

  -- Some fundamental data types in the Lean library are instances of enumerated types.
namespace hideme  -- use `hide₁` to avoid conflicts with stdlib.
  inductive empty : Type  -- an inductive data type with no constructors
  inductive unit : Type | star : unit
  inductive bool : Type | ff : bool | tt : bool
end hideme

    /- As an exercise, think about the introduction and elimination rules for these types,
       and define boolean operations `band`, `bor`, `bnot` on the boolean, and verifying 
       common identities; e.g., define `band` using a case split: -/
namespace hideme
  open hideme.bool   (renaming cases_on → cases_on)
  def b_and (b1 b2 : bool) : bool := cases_on b1 ff b2
  def b_or (b1 b2 : bool) : bool := cases_on b1 b2 tt 
  def b_not (b : bool) : bool := cases_on b tt ff 
  #reduce b_and tt tt   -- result: tt
  #reduce b_and ff tt   -- result: ff
  #reduce b_or tt ff    -- result: tt
  #reduce b_or ff ff    -- result: ff
  #reduce b_not ff      -- result: tt
  #reduce b_not tt      -- result: ff
end hideme
-- Similarly, most identities can be proved by introducing suitable case splits followed by `rfl`.

#print "==========================================="
#print "Section 7.2. Constructors with Arguments"
#print " "

namespace Sec_7_2
/- Enumerated types are a special case of inductive types, in which constructors take 
   no arguments. In general, a "construction" can depend on data, which is then represented 
   in the constructed argument. Consider the definitions of the product and sum types. -/

  universes u v
  namespace hide₂
    inductive prod (α : Type u) (β : Type v) | mk : α → β → prod
    inductive sum (α : Type u) (β : Type v) | inl {} : α → sum | inr {} : β → sum
  end hide₂
  
  /- To define a function on prod α β, we assume input of the form prod.mk a b, and specify
     the output in terms of a and b. For example, here is the definition of the two projections 
     for prod.  -/
  -- namespace custom_fst_snd
  --   open hide₂.prod (renaming rec_on → rec_on)
  --   -- def fst {α : Type u} {β : Type v} (p : prod α β) : α := rec_on p (λ a b, a)
  --   -- def snd {α : Type u} {β : Type v} (p : prod α β) : β := rec_on p (λ a b, b)
  -- end custom_fst_snd

  -- We could also use the std lib α × β and (a, b) (notation for prod α β and prod.mk a b, resp)
  namespace hide₃
    def fst {α : Type u} {β : Type v} (p : α × β) : α := prod.rec_on p (λ a b, a)
    def snd {α : Type u} {β : Type v} (p : α × β) : β := prod.rec_on p (λ a b, b)
    /- `fst` takes pair `p`, applies recursor `prod.rec_on p (λ a b, a)`---which interprets 
      `p` as pair `prod.mk a b`---then uses the 2nd arg to determine what to do with a and b. -/

    -- another example
    def prod_example₁ (p : bool × ℕ) : ℕ := prod.rec_on p (λ b n, cond b (2 * n) (2 * n + 1))
    #reduce prod_example₁ (tt, 3)  -- result: 6
    #reduce prod_example₁ (ff, 3)  -- result: 7

    -- `cond` has the same effect as `bool.rec_on b t2 t1` (note the transposition of t2 t1)
    def prod_example₂ (p: bool × ℕ): ℕ:= prod.rec_on p (λ b n, bool.rec_on b (2 * n + 1) (2 * n))
    #reduce prod_example₂ (tt, 3)  -- result: 6
    #reduce prod_example₂ (ff, 3)  -- result: 7

    def prod_example₃ (p : bool × ℕ) : ℕ := if (p.fst) then 2* p.snd else 2* p.snd + 1
    #reduce prod_example₃ (tt, 3)  -- result: 6
    #reduce prod_example₃ (ff, 3)  -- result: 7

    /- `sum` has two constructors, `inl` and `inr` and each takes one explicit argument. 
      To define a function on `sum α β`, we must handle 2 cases: if the input is of the form
      `inl a` (resp., `inr b`) then we must specify an output value in terms of a (resp `b`). -/

    def sum_example (s : ℕ ⊕ ℕ) : ℕ := sum.cases_on s (λ n, 2*n) (λ n, 2*n + 1)

    #reduce sum_example (sum.inl 3) -- result: 6
    #reduce sum_example (sum.inr 3) -- result: 7
  end hide₃

  /- A type with multiple constructors is *disjunctive*; e.g. an element of `sum α β` is either 
     of the form `inl a` *or* of the form `inl b`. Further, each constructor with multiple 
     arguments introduces conjunctive information; e.g., from an element `prod.mk a b` of 
     `prod α β` we can extract `a` *and* `b`. An arbitrary inductive type can include both 
     features, by having any number of constructors, each of which takes any number of arguments.
  -/

  -- Lean's inductive definition syntax allows named arguments to constructors before the colon.
  namespace custom_prod₂
    -- instead of `inductive prod (α : Type u) (β : Type v) | mk : α → β → prod`
    -- we could have used
    inductive prod (α : Type) (β : Type) | mk (fst : α) (snd : β) : prod
    inductive sum (α : Type) (β : Type) | inl {} (a : α) : sum | inr {} (b : β) : sum
    -- These result in essentially the same types as before. `{}` refers to params, `α` and `β`.

    -- The following gives errors because naming fst and snd is not the same as defining them.
    --   def prod_example₄ (p : prod bool ℕ) : ℕ := if (p.fst) then 2* p.snd else 2* p.snd + 1
    --   #reduce prod_example₄ (prod.mk tt 3)  
    -- See the fix in custom_prod₃ below
  end custom_prod₂

  /- A type, like `prod`, that has only one constructor is purely conjunctive: 
     the constructor simply packs the list of arguments into a single piece of data, 
     essentially a tuple where 

       *THE TYPE OF SUBSEQUENT ARGUMENTS CAN DEPEND ON THE TYPE OF THE INITIAL ARGUMENT*

     We can think of such a type as a "record" or a "structure."  -/

  /- In Lean, the keyword `structure` can be used to define such an inductive type, as well 
     as its projections, at the same time. -/
  namespace custom_prod₃
    structure prod (α β : Type) := mk :: (fst : α) (snd : β)
    /- This simultaneously introduces the inductive type, `prod`, its constructor, `mk`, the
       usual eliminators (`rec` and `rec_on`), as well as the projections, `fst` and `snd`.
       So our previous example, from `custom_prod`, works now. -/
    def prod_example₄ (p : prod bool ℕ) : ℕ := if (p.fst) then 2* p.snd else 2* p.snd + 1
    #reduce prod_example₄ (prod.mk tt 3)  
    #reduce prod_example₄ (prod.mk ff 3)  

  end custom_prod₃

  /- If you don't name the constructor, Lean uses `mk` as a default. For example, the 
     following defines a record to store a color as a triple of RGB values: -/

  structure color := (red : ℕ) (green : ℕ) (blue : ℕ)
  def yellow := color.mk 255 255 0
  #reduce color.red yellow     -- result: 255  (`color.red` is projection onto first component)
  #reduce color.green yellow   -- result: 255
  #reduce color.blue yellow    -- result: 0

  /- ALGEBRAIC STRUCTURES. -/

  -- `structure` IS ESPECIALLY USEFUL FOR DEFINING ALGEBRAIC STRUCTURES
  -- and Lean provides substantial infrastructure to support working with them. 

  -- SEMIGROUPS --
  structure Semigroup := (univrs : Type u) 
    (mul : univrs → univrs → univrs)
    (mul_assoc : ∀ a b c, mul (mul a b) c = mul a (mul b c))

  -- ==> More examples in CHAPTER 9!!!!!!! <==
  -- (okay, but we should insert a short example of instantiating a semigroup here)
  def mysg := Semigroup.mk nat (λ x y, x * y)
  #check mysg

  -- Let's try to define lattices on our own, using what we already know.

  -- LATTICES --
  structure Lattice := (univrs : Type u)
    (meet: univrs → univrs → univrs)
    (join: univrs → univrs → univrs)
    (idempotent_meet : ∀ x,  meet x x = x)
    (idempotent_join : ∀ x,  join x x = x)
    (commutative_meet : ∀ x y, meet x y = meet y x)
    (commutative_join : ∀ x y, join x y = join y x)
    (associative_meet : ∀ x y z, meet (meet x y) z = meet x (meet y z))
    (associative_join : ∀ x y z, join (join x y) z = join x (join y z))
    (absorptive_meet : ∀ x y, meet x (join x y) = x)
    (absorptive_join : ∀ x y, join x (meet x y) = x)

  -- Okay, fine, so now how do we *use* this structure to do lattice theory.
  ----------------------------------------------------------------------------
  def mylat := Lattice.mk nat (λ x y, if (x < y) then x else y) (λ x y, if (y < x) then x else y) 
  #check mylat

  -- Recall, sigma types are also known as the "dependent product" type:
  namespace hide₄
    inductive sigma {α : Type u} (β : α → Type v) | dpair : Π a : α, β a → sigma
    -- This looks confusing because sigma is not a pi type.  But the constructor
    -- is a function whose domain is a pi type and whose codomain is sigma.

    -- Two more inductive types in the library are `option` and `inhabited`.
    inductive option (α : Type u) | none {} : option | some    : α → option
    inductive inhabited (α : Type u) | mk : α → inhabited
  end hide₄

  -- `option` type enables us to define partial functions

  /- In the semantics of dependent type theory, there is no built-in notion of a partial 
     function. Every element of a function type `α → β` or a Pi type `Π x : α, β` is assumed 
     total. The `option` type enables us to represent partial functions. An element of 
     `option β` is either `none` or of the form `some b`, for some value `b : β`. Thus,
     `α → option β` is the type of partial functions from `α` to `β`; if `a : α`, then 
     `f a` either returns `none`, indicating the `f` is "undefined" at `a`, or `some b`. -/

  /- An element of `inhabited α` is simply a witness to existence of an element of `α`. 
     `inhabited` is actually an example of a **type class** in Lean: Lean can be told that
     suitable base types are inhabited, and can automatically infer that other constructed 
     types are inhabited on that basis. -/

  /- As exercises, develop a notion of composition for partial functions from `α` to `β` and 
     `β` to `γ`, and show that it behaves as expected. -/

  namespace exercise₁
    inductive option (α : Type u) 
    | none {} : option 
    | some : α → option

    def compose (α β γ: Type u) (f : α → option β) (g : β → option γ) (x: α) : option γ := 
      option.cases_on (f x) (option.none) (λ y, g y)
  end exercise₁

  /- Also, show that `bool` and `nat` are inhabited, that the product of two inhabited types
     is inhabited, and that the type of functions to an inhabited type is inhabited. -/
  namespace exercise₂
    inductive inhabited (α : Type u) | mk : α → inhabited
    theorem bool_is_inhabited : inhabited bool := inhabited.mk tt 
    theorem nat_is_inhabited : inhabited nat := inhabited.mk 0 
    #check bool_is_inhabited
    #check nat_is_inhabited
  end exercise₂

end Sec_7_2


#print "==========================================="
#print "Section 7.3. Inductively Defined Propositions"
#print " "
-- https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html#inductively-defined-propositions

/- Inductively defined types can live in any type universe, including the bottom-most one, 
   `Prop`. In fact, this is exactly how the logical connectives are defined. -/

namespace Sec_7_3
  namespace hide₅
    inductive false : Prop
    inductive true : Prop | intro : true
    inductive and (a b : Prop) : Prop | intro : a → b → and
    inductive or (a b : Prop) : Prop | intro_left : a → or | intro_right : b → or

    -- Alternatively, we could give names to the inhabitants:
    inductive and' (P Q : Prop) : Prop | intro (a : P) (b : Q) : and'
    inductive or' (P Q : Prop) : Prop | inl (a : P) : or' | inr (b : Q) : or'

    variables p q: Prop
    #check @and.intro p
    #check @and.intro p q
    #check @and'.intro p
    #check @and'.intro p q
    #check @or.intro_left p
    #check @or'.inl p
  end hide₅

  -- Think about how these give rise to the intro and elim rules we've already seen.

  -- There are rules that govern what the eliminator of an inductive type can eliminate to;
  -- that is, what kinds of types can be the target of a recursor.

  /- Roughly speaking, what characterizes inductive types in Prop is that one can only 
     eliminate to other types in Prop. This agrees with the fact that if `p : Prop`, then
     an element `hp : p` carries no info. (There is one exception discussed below.) -/

  -- Even the existential quantifier is inductively defined:
  namespace hide₆
    universe u
    inductive Exists {α : Type u} (p : α → Prop) : Prop | intro : ∀(a : α), p a → Exists
    inductive Egzsts {α : Type u} (p : α → Prop) : Prop | intro (w : ∀(a : α), p a) : Egzsts
    def exists.intro := @Exists.intro

    variables (α : Type) (p : α → Prop) (a : α)

    #check @exists.intro
    #check @exists.intro α
    #check @exists.intro α p
    #check @exists.intro α p a
  end hide₆ 

  -- The notation `∃ x : α, p` is syntactic sugar for `Exists (λ x : α, p)`.

  /- The defs of `false`, `true`, `and`, and `or` are analogous to the defs of 
     `empty`, `unit`, `prod`, and `sum`. The difference is the former yield
     elements of `Prop`, and the latter yield elements of `Type u` for some `u`. -/

  -- Similarly, `∃ x : α, p` is a `Prop`-valued variant of `Σ x : α, p`.

  /- Another inductive type, denoted `{x : α | p}`, is sort of a hybrid between 
     `∃ x : α, P` and `Σ x : α, P`. It is the `subtype` type. -/

  namespace hide₇
    universe u
    inductive subtype {α : Type u} (p : α → Prop) | mk : Π(x : α), p x → subtype
    inductive subtype_alt {α : Type u} (p : α → Prop) | mk (w : Π(x : α), p x) : subtype_alt
  end hide₇

 -- This next example is unclear to me.
 namespace confusing_example
   universe u
   variables {α : Type u} (p : α → Prop)
   --  ==========> UNRESOLVED QUESTIONS:     <==========
   #check subtype p        -- why is the result `subtype p : Type u` ??
   #check {x : α // p x }  -- why is the result `{x // p x } : Type u` ??
 end confusing_example
 -- The notation `{x : α // p x}` is syntactic sugar for subtype `(λ x : α, p x)`. 
end Sec_7_3

#print "==========================================="
#print "Section 7.4. Defining the Natural Numbers"
#print " "
-- https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html#defining-the-natural-numbers

namespace hidden
  /- The inductively defined types we have seen so far are "flat": constructors wrap data and
     insert it into a type, and the corresponding recursor unpacks the data and acts on it. 
     Things get more interesting when constructors act on elements of the type being defined. -/

  -- -- A canonical example:
  inductive nat : Type 
  | zero : nat 
  | succ : nat → nat

/- The recursor for `nat` defines a dependent function `f` from `nat` to any domain, 
   that is, `nat.rec` defines an element `f` of `Π n : nat, C n` for any `C : nat → Type`. 
   It has to handle two cases: the case where the input is zero, and the case where the 
   input is of the form succ n for some n : nat. 
   First case: we specify a target value of appropriate type. 
   Second case: the recursor assumes f(n) has been computed and then uses the 
   next argument to specify a value for f (succ n) in terms of n and f n. -/
 
  #check @nat.rec_on -- result:  Π {C : nat → Sort u_1} (n : nat), -- arg 1: major premise
                     --           C nat.zero →                     -- arg 2: minor premise 1
                     -- (Π (a : nat), C a → C (nat.succ a))        -- arg 3: specifies how to 
                     --                                                       construct f(n+1) 
                     --                                                       given n and f(n)
                     -- → C n                                      -- output type

  /-(motive) The implicit argument, `C`, is the codomain of the function being defined. 
             In type theory we say `C` is the *motive* for the elimination/recursion, 
             since it describes the kind of object we're constructing. 
  - (major premise) `n : nat`, is the input to the function, aka the `major premise`. 
  - (minor premise) the two arguments after say how to compute the zero and succ cases, 
                    as described above. They are aka the `minor premises`. -/

  namespace nat

    -- predecessor
    def pred (n : nat) : nat := nat.rec_on n zero (λ n pred_n, n)

    #reduce pred zero
    #reduce pred (succ zero)
    #reduce pred (succ (succ zero))
    #reduce pred (succ (succ (succ zero)))

    /-Consider `add m n` on natural numbers. Fix `m` and define `add` by recursion on `n`. 
      + base case: let `add m zero` be `m`. 
      + succ step: assume `add m n` is given; let `add m (succ n)` be `succ (add m n)`. -/

    def add (m n: nat): nat:= nat.rec_on n m              -- if n = zero, just return m
                              (λ n add_m_n, succ add_m_n) -- otherwise, given n and the 
                                                          -- result (add_m_n := add m n), 
                                                          -- return add_m_n + 1

    /- Let's disect the defn of `add` in more detail.
       + `nat.rec_on n` says "recurse on n".  
       + (base case) The symbol `m` gives the answer in case n=zero.  
       + (induction step) `(λ n add_m_n, succ add_m_n)` gives the answer in all other 
                          (n > 0) cases. The first argument to the λ abstraction is `n`, 
                          which means assume we know `add_m_n`---the value returned on 
                          input `m n`; use this info to compute the value returned when 
                          the input is `m (succ n)`; namely, return `succ add_m_n`.-/

    #reduce add (succ zero) (succ (succ zero)) -- result: succ (succ (succ zero))

    -- Can we recurse on m instead of n?  Yes, of course.
    def add' (m n : nat) : nat := nat.rec_on m n (λ m add_m_n, succ add_m_n)
    #reduce add' (succ zero) (succ (succ zero)) -- same result as above


    instance : has_zero nat := has_zero.mk zero
    instance : has_add nat := has_add.mk add

    theorem add_zero (m : nat) : add m zero = m := rfl
    theorem add_succ (m n : nat) : add m (succ n) = succ (add m n) := rfl
  /- Proving `0 + m = m`, however, requires induction. The induction principle is just a 
     special case of the recursion principle when the codomain `C n` is an element of `Prop`. 
     It represents the familiar pattern of proof by induction: to prove `∀ n, C n`, first
     prove `C 0`, and then, for arbitrary `n`, assume `ih : C n` and prove `C (succ n)`. -/

    theorem zero_add (n : nat) : add zero n = n := nat.rec_on n
      (show add zero zero = zero, from rfl)
      (assume n, assume ih : add zero n = n,
        show add zero (succ n) = succ n, from 
          calc add zero (succ n) = succ (add zero n) : rfl
                             ... = succ n : by rw ih)

    theorem zero_add' (n : nat) : add zero n = n := nat.rec_on n 
    rfl (λ n ih, by simp only [add_succ, ih])
  /- Remarks: (1) when `nat.rec_on` is used in a proof, it's the induction principle in disguise. 
     The `rewrite` and `simp` tactics tend to be effective in proofs like these.
     (2) Leaving off the `only` modifier would be misleading because `zero_add` is declared 
     in the standard library. Using `only` guarantees `simp` uses only the identities listed.-/

  /- Associativity of addition: ∀ m n k, m + n + k = m + (n + k). 
     The hardest part is figuring out which variable to do the induction on. 
     Since addition is defined by recursion on the second argument, k is a good guess. -/
    theorem add_assoc (m n k : nat) : add (add m n) k = add m (add n k) := nat.rec_on k
      (show add (add m n) zero = add m (add n zero), from rfl)
      (assume k, assume ih : add (add m n) k = add m (add n k), 
        show add (add m n) (succ k) = add m (add n (succ k)), from
          calc add (add m n) (succ k) = succ (add (add m n) k) : rfl
                            ... = succ (add m (add n k)) : by rw ih
                            ... = add m (succ (add n k)) : rfl
                            ... = add m (add n (succ k)) : rfl)

    -- once again, there is a one-line proof
    theorem add_assoc' (m n k : nat) : add (add m n) k = add m (add n k) := nat.rec_on k
      rfl (λ k ih, by simp only [add_succ, ih])

    theorem succ_add (m n : nat) : add (succ m) n = succ (add m n) := nat.rec_on n
      (show add (succ m) zero = succ (add m zero), from rfl)
       (assume n,
         assume ih : add (succ m) n = succ (add m n),
         show add (succ m) (succ n) = succ (add m (succ n)), from
           calc add (succ m) (succ n) = succ (add (succ m) n) : rfl
                                  ... = succ (succ (add m n)) : by rw ih
                                  ... = succ (add m (succ n)) : rfl)

    -- Commutativity of addition:
    theorem add_comm (m n : nat) : add m n = add n m := nat.rec_on n
      (show add m zero = add zero m, by rw [zero_add, add_zero])
      (assume n,
      assume ih : add m n = add n m, show add m (succ n) = add (succ n) m, from
        calc add m (succ n) = succ (add m n) : rfl
                        ... = succ (add n m) : by rw ih
                        ... = add (succ n) m : by simp only [succ_add])

    -- Here are the shorter versions of the last two theorems:
    theorem succ_add' (m n : nat) : add (succ m) n = succ (add m n) := 
      nat.rec_on n rfl (λ n ih, by simp only [add_succ, ih])

  theorem add_comm' (m n : nat) : add m n = add n m := nat.rec_on n 
    (by simp only [zero_add, add_zero])
    (λ n ih, by simp only [add_succ, ih, succ_add])

  end nat
end hidden


#print "==========================================="
#print "Section 7.5. Other Recursive Data Types"
#print " "
-- https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html#other-recursive-data-types

-- Here are some more examples of inductively defined types.
namespace hidden
  open hidden.nat

  -- For any type, α, the type list α of lists of elements of α is defined in the library.
  universe u
  inductive list (α : Type u)
  | nil {} : list
  | cons : α → list → list

  namespace list
  
  variable {α : Type}
  
  notation h :: t := cons h t

  def length (l : list α ) : nat := list.rec_on l zero (λ (x: α) (xs: list α) n, succ n)
  
  #reduce length nil
  #reduce length (cons zero (cons zero nil))
  lemma len_nil {α: Type} : length (nil: list α) = zero := rfl

  lemma list_add_one (x: nat) (t : list nat) : length (x :: t) = succ (length t) := rfl

  def append (s t : list α) : list α := 
    list.rec t (λ (x: α) (l: list α) (u: list α), x :: u) s
  /- Dissection of append: 
     The first arg to `list.rec` is `t`, meaning return `t` when `s` is `nil`.
     The second arg is `(λ x l u, x :: u) s`.  I believe this means the following:
     assuming `u` is the result of `append l t`, then `append (x :: l) t` results
     in `x :: u`.  
  -/

  /- To give some support for the claim that the foregoing interpretation is (roughtly) 
     correct, let's make the types explicit and verify that the definition still type-checks: -/
  def append' (s t : list α) : list α := list.rec (t: list α) 
                (λ (x : α) (l : list α) (u: list α), x :: u) (s : list α)


  #check nil                       -- nil : list ?M_1
  #check (nil: list ℕ)         -- nil : list ℕ
  #check cons 0 nil                -- 0 :: nil : list ℕ
  #check cons "a" nil              -- 0 :: nil : list string
  #check cons "a" (cons "b" nil)   -- a :: b :: nil : list string

  notation s ++ t := append s t
  --notation a + b := add a b

  theorem nil_append (t : list α) : nil ++ t = t := rfl
  theorem nil_append' (t : list α) : append' nil t = t := rfl
  theorem cons_append (x : α) (s t : list α) : (x :: s) ++ t = x :: (s ++ t) := rfl

  theorem append_associative (r s t : list α) : r ++ s ++ t = r ++ (s ++ t) := list.rec_on r
  rfl
  (assume (x: α) (r : list α),
    assume ih: r ++ s ++ t = r ++ (s ++ t),
    show (x::r) ++ s ++ t = (x::r) ++ (s ++ t), from
      calc (x::r) ++ s ++ t = x::(r++s) ++ t: by rw [cons_append]
                        ... = x::((r++s)++t) : by rw [cons_append]
                        ... = x::(r++(s++t)) : by rw [ih]
                        ... = (x::r)++(s++t) : by rw [cons_append])


  -- Lean allows us to define iterative notation for lists:

  notation `{` l:(foldr `,` (h t, cons h t) nil) `}` := l

  section
    --open hidden.nat
    #check {1,2,3,4,5}               -- Lean assumes this is a list of nats
    #check ({1,2,3,4,5} : list int)  -- Forces Lean to take this as a list of ints.
  end 

  -- As an exercise, prove the following:
  theorem append_nil (t : list α) : t ++ nil = t := 
    begin 
      induction t with a t ih,
      refl,
      simp [nil_append,cons_append,ih]
    end

  theorem append_nil_first_try (t : list α) : t ++ nil = t := 
    list.rec_on t 
      rfl  -- more explicitly, `(show (append nil nil) = nil, from rfl)`
      (assume (x : α) (t : list α) (ih : append t nil = t),
        show append (x :: t) nil = (x :: t), from
          calc append (x :: t) nil = x :: append t nil  : cons_append x t nil
                               ... = x :: t             : by rw ih)

  theorem append_nil_second_try (t : list α) : t ++ nil = t := list.rec_on t 
    rfl                                                        -- base step
    (λ x t (ih : append t nil = t), by simp [cons_append, ih]) -- induction step

 theorem append_assoc (r s t : list α) : r ++ s ++ t = r ++ (s ++ t) := 
  begin induction r with a r ih,
    simp [nil_append],              -- base step
    simp [cons_append, ih]                   -- induction step
  end
  
  -- binary trees
  inductive binary_tree
  | leaf : binary_tree
  | node : binary_tree → binary_tree → binary_tree

  -- countably branching trees
  inductive cbtree
  | leaf : cbtree
  | sup : (nat → cbtree) → cbtree

  namespace cbtree
  
  def succ (t : cbtree) : cbtree := sup (λ n, t)  -- Note: (λ n, t) is a thunk; i.e., a way to
                                                  -- view t as a function of type ℕ → cbtree.

  /- Note the similarity to nat's successor.  The third cbtree after t would be 
     `sup (λ n, sup (λ n, sup (λ n, t))` -/

  def omega : cbtree := sup (λ n, nat.rec_on n leaf (λ n t, succ t))
  end cbtree
  end list
           
end hidden


#print "==========================================="
#print "Section 7.6. Tactics for Inductive Types"
#print " " 
-- https://leanprover.github.io/theorem_proving_in_lean/inductive_types.html#tactics-for-inductive-types

namespace hidden
  /- There are a number of tactics designed to work with inductive types effectively. 
     The `cases` tactic works on elements of an inductively defined type by decomposing 
     the element into the ways it could be constructed. -/

  universe u
  open hidden.list
  open hidden.nat

  variable p : nat → Prop
  example (hz : p zero) (hs : ∀ n, p (succ n)) : ∀ n, p n :=
    begin intro n, cases n, exact hz, apply hs end
  
  /- `cases` lets you choose names for arguments to the constructors using `with`. 
     For example, we can choose the name `m` for the argument to `succ`, so the second 
     case refers to `succ m`. More importantly, `cases` detects items in the local context 
     that depend on the target variable. It reverts these elements, does the split, and 
     reintroduces them. In the example below, notice that `h : n ≠ 0` becomes `h : 0 ≠ 0` 
     in the first branch, and `h : succ m ≠ 0` in the second.-/

  example (n : nat) (h : n ≠ zero) : succ (hidden.nat.pred n) = n :=
    begin
      cases n with m,  -- name cases using variable m
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        { apply (absurd rfl h) },
        -- goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        reflexivity
    end

  -- `cases` can be also be used to produce data and define functions.
  def f (n : nat) : ℕ := begin cases n, exact 3, exact 7 end

  example : f 0 = 3 := rfl
  example : f (succ (succ zero))  = 7 := rfl
  -- in fact, we can prove that f n is constantly 7, except when n = 0.
  example  (n : nat) (h : n ≠ 0) : (f n) = 7 := 
    begin
      cases n,
      { apply (absurd rfl h) },  -- goal: 0 ≠ 0 ⊢ f 0 = 7
      reflexivity                -- goal: (succ a ≠ 0) ⊢ f (succ a) = 7
    end

  variable α : Type u
  
  def length {α : Type u} (l : list α ) : nat := list.rec_on l zero (λ (x: α) (xs: list α) n, succ n)
  
 -- lemma len_nil : (length nil) = zero := rfl
  -- Now let's define a function that takes a single argument of type `tuple`.
  
  -- First define the type `tuple`.
  -- Recall, we define a type that satisfies a predicate like this:
  def tuple {α : Type u} (n : nat) := subtype (λ (l : list α), (length l) = n)
    --{ l : list α // list.length l = n }  -- (this didn't work for me) 

  --variables {α : Type u} {n : nat}

  def ff {n : nat} (t : @tuple nat n) : nat := begin cases n, exact zero, exact succ (succ (succ zero)) end

  def my_tuple : tuple (succ (succ (succ zero))) := ⟨(cons zero (cons (succ zero) (cons zero nil))), rfl⟩

  example : ff my_tuple = succ ( succ ( succ zero)) := rfl

  -- As above, we prove that f t is constantly 7, except when t.length=0.
  example  (n : nat) (t : tuple n) (h : n ≠ zero) : ff t = succ (succ (succ zero)) := 
    begin
      cases n,
      apply (absurd rfl h),  -- goal: 0 ≠ 0 ⊢ f 0 = 7
      reflexivity            -- goal: (a : ℕ) (succ a ≠ 0) (t : tuple α (succ a)) ⊢ f t = 7
    end

  /- Just as `cases` is used to carry out proof by cases, the `induction` tactic is used 
     for proofs by induction. In contrast to `cases`, the argument to `induction` can only 
     come from the local context. -/

  theorem zero_add (n : nat) : add zero n = n :=
  begin
    induction n with n ih,
      refl,
      rw [add_succ, ih]
  end
  
  -- The `case` tactic identifies each case with named arguments, making the proof clearer:
  theorem zero_add' (n : nat) : add zero n = n :=
  begin
    induction n,
    case zero : { refl },
    case succ : n ih { rw [add_succ, ih] }
  end

  theorem succ_add' (m n : nat) : add (succ m) n = succ (add m n) :=
  begin
    induction n,
    case zero : { refl },
    case succ : n ih { simp [add_succ, ih] }
  end

  theorem add_comm' (m n : nat) :add m n = add n m :=
  begin
    induction n,
    case zero : { rw zero_add, refl },
    case succ : n ih { rw [add_succ, ih, succ_add] }
  end

  -- Here are terse versions of the last three proofs.
  theorem zero_add'' (n : nat) : add zero n = n := 
    by induction n; simp only [*, hidden.nat.add_zero, add_succ]

  theorem succ_add'' (m n : nat) : add (succ m) n = succ (add m n) := 
    by induction n; simp only [*, hidden.nat.add_zero, add_succ]

  theorem add_comm'' (m n : nat) : add m n = add n m :=
  by induction n; simp only [*, zero_add, hidden.nat.add_zero, add_succ, succ_add]

  theorem add_assoc'' (m n k : nat) : add (add m n) k = add m (add n k) :=
  by induction k; simp only [*, hidden.nat.add_zero, add_succ]

  /-We close this section a tactic designed to assist with inductive types---the injection tactic. 
    The elements of an inductive type are freely generated, that is, the constructors are injective 
    and have disjoint ranges. The injection tactic is designed to make use of this fact.  -/

  example (m n k : nat) (h : succ (succ m) = succ (succ n)) : 
    n + k = m + k :=
  begin
    injection h with h',   -- adds `h' : succ m = succ n` to the context
    injection h' with h'', -- adds `h'' : m = n` to the context
    rw h''
  end
  -- The plural variant, `injections`, applies `injection` to all hypotheses repeatedly. 
  -- It still allows you to name the results using `with`.

  example (m n k : nat) (h : succ (succ m) = succ (succ n)) : 
    n + k = m + k :=
  begin
    injections with h' h'',
    rw h''
  end

  /- The `injection` and `injections` tactics will also detect contradictions that arise when 
     different constructors are set equal to one another, and use them to close the goal. -/

  example (m n : nat) (h : succ m = 0) : n = n + succ (succ (succ zero)) := by injections
  example (m n : nat) (h : succ m = 0) : n = n + succ (succ (succ zero)) := by contradiction
  example (h : 7 = 4) : false := by injections

  /-As the 2nd example shows, `contradiction` also detects contradictions of this form. 
    But the `contradiction` tactic does not solve the third goal, while `injections` does. -/

end hidden


#print "==========================================="
#print "Section 7.7. Inductive Families"
#print " "

namespace Sec_7_7

  /-So far, you have seen that Lean allows you to introduce inductive types with any number of 
    recursive constructors. In fact, a single inductive definition can introduce an indexed 
    *family* of inductive types, in a manner we now describe. -/

  /-An inductive family is an indexed family of types defined by a simultaneous induction of 
    the following form:

        inductive foo : ... → Sort u :=
        | constructor₁ : ... → foo ...
        | constructor₂ : ... → foo ...
          ...
        | constructorₙ : ... → foo ...

    An ordinary inductive definition constructs an element of some `Sort u.` 
    The more general version constructs a function `... → Sort u`, where 
    "`...`" denotes a sequence of argument types, also known as *indices*. 
    Each constructor then constructs an element of some member of the family.-/
    
    --One example is `vector α n`, for vectors of elements of `α` of length `n`.
  
  namespace hidden
    open nat
    universe u
    inductive vector (α : Type u) : nat → Type u
    | nil {}                              : vector zero
    | cons {n : ℕ} (a : α) (v : vector n) : vector (succ n)

    -- Notice that `cons` takes an `α` and a `vector α n` and returns a 
    -- `vector α (succ n)`, thereby using an element of one member of the 
    -- family to build an element of another.

    -- A more exotic example is given by the definition of the equality type in Lean:
    inductive eq {α : Sort u} (a : α) : α → Prop | refl : eq a

    /-For each fixed `α : Sort u` and `a : α`, this definition constructs a family of 
      types `eq a x`, indexed by `x : α`.  However, there is only one constructor, `refl`, 
      that is an element of `eq a a`. Intuitively, the only way to construct a proof 
      of `eq a x` is to use reflexivity, in the case where `x` is `a`. Note that 
      `eq a a` is the only inhabited type in the family of types `eq a x`.  -/

    universe v
    variables (α : Type u) (a b x: α)
    #check eq a a   #check eq a x
    example : eq a a := eq.refl a
    -- example : eq a x := eq.refl a    -- (error)
  end hidden

  -- The elimination principle generated by Lean is as follows:
  universes u v
  #check (@eq.rec_on : Π {α : Sort u} {a : α} {C : α → Sort v} {b : α}, eq a b → C a → C b)

  /-It's remarkable that all the basic axioms for equality follow from the constructor 
    `refl` and the eliminator `eq.rec_on`. The definition of equality is atypical, 
    however; see discussion in the next section. -/

  namespace hidden
    -- The recursor `eq.rec_on` is also used to define substitution:
    @[elab_as_eliminator]
    theorem subst {α: Type u} {a b: α} {p: α → Prop} (h₁: eq a b) (h₂: p a): p b := 
      eq.rec h₂ h₁
    /-Using the recursor with `h₁ : eq a b`, we may assume `a` and `b` are the same, 
      in which case, `p b` and `p a` are the same. The definition of `subst` is marked 
      with an elaboration hint, as described in Section 6.10. -/
  end hidden

  -- EXERCISES
  namespace hidden
    /- It is not hard to prove that `eq` is symmetric and transitive. In the following example, 
       we prove `symm` and leave as exercise the theorems `trans` and `congr` (congruence). -/
    theorem symm {α: Type u} {a b: α} (h: eq a b): eq b a := subst h (eq.refl a)

    theorem trans {α: Type u} {a b c: α} (h₁: eq a b) (h₂: eq b c): eq a c := 
      eq.rec h₁ h₂ 

    theorem congr {α β: Type u} {a b: α} (f: α → β) (h: eq a b): eq (f a) (f b) :=  
      subst h (eq.refl (f a))
  end hidden

  -- In the type theory literature, there are further generalizations of inductive definitions, 
  -- for example, the principles of *induction-recursion* and *induction-induction*. 
  -- These are not supported by Lean.
end Sec_7_7

#print "==========================================="
#print "Section 7.8. Axiomatic Details"
#print " "

/-This section is for those interested in the axiomatic foundations.

  We have seen that the constructor to an inductive type takes 
  + **parameters** = the arguments that remain fixed throughout the inductive construction.  
  + **indices** = the arguments parameterizing the family of types under construction. 
  
  Each constructor should have a Pi type whose argument types are built up from 
  (a) previously defined types, (b) parameter types, (c) index types and (d) the inductive 
  family currently being defined. 
  
  If (d) is present at all, then it occurs only *strictly positively*. This means simply
  that any argument to the constructor in which (d) occurs is a Pi type in which the 
  inductive type under definition occurs only as the resulting type, where the indices 
  are given in terms of constants and previous arguments.

  Since an inductive type lives in `Sort u` for some `u`, it is reasonable to ask, 
  "in what universe levels can `u` be instantiated?" 
    
  Each constructor `c` in the defn of a family `C` of inductive types is of the form

      c : Π (a : α) (b : β[a]), C a p[a,b]

  where `a` is a sequence of data type parameters, `b` is the sequence of arguments to 
  the constructors, and `p[a, b]` are the indices, that determine which element of the 
  inductive family the construction inhabits. 
  
  (Note that this description is somewhat misleading in that the arguments to the 
  constructor can appear in any order as long as the dependencies make sense.) 
  
  The constraints on the universe level of `C` fall into two cases, depending on whether 
  or not the inductive type is specified to land in `Prop` (that is, `Sort 0`).

  Let us first consider the case where the inductive type does *not* land in `Prop`. 
  Then the universe level `u` is constrained to satisfy the following:

    - For each constructor `c`, and each `βk[a]` in the sequence `β[a]`, 
      if `βk[a] : Sort v`, then `u ≥ v`.

  In other words, the universe level `u` is required to be at least as large as the 
  universe level of each type that represents an argument to the constructor.

  When the inductive type lands in `Prop`, there are no constraints on the universe 
  levels of the constructor arguments. But these universe levels do have a bearing on 
  the elimination rule. Generally speaking, for an inductive type in `Prop`, the motive 
  of the elimination rule is required to be in `Prop`.

  There is an exception to this last rule: we are allowed to eliminate from an 
  inductively defined `Prop` to an arbitrary `Sort` when there is only one constructor 
  and each constructor argument is either in `Prop` or an index. In this case the 
  elimination does not make use of any information other than the mere fact that the 
  argument type is inhabited. This special case is known as *singleton elimination*.

  We have already seen singleton elimination in applications of `eq.rec`, the eliminator 
  for the inductively defined equality type. We can use an element `h : eq a b` to cast 
  an element `t' : p a` to `p b` even when `p a` and `p b` are arbitrary types, because 
  the cast does not produce new data; it only reinterprets the data we already have. 
  Singleton elimination is also used with heterogeneous equality and well-founded 
  recursion, which will be discussed in a later chapter. -/


#print "==========================================="
#print "Section 7.9. Mutual and Nested Inductive Types"
#print " "

/-We now consider two useful generalizations of inductive types that Lean supports 
  by "compiling" them down to the more primitive kinds of inductive types described 
  above. In other words, Lean parses the more general definitions, defines auxiliary 
  inductive types based on them, and then uses the auxiliary types to define the 
  ones we really want. Lean's equation compiler, described in the next chapter, 
  is needed to make use of these types effectively. -/

/-First, Lean supports *mutually defined* inductive types. The idea is that we can 
  define two (or more) inductive types at the same time, where each one depends on
  the other(s). -/

namespace hide791 
  mutual inductive even, odd
    with even : ℕ → Prop
    | even_zero : even 0
    | even_succ : ∀ n, odd n → even (n + 1)
    with odd : ℕ → Prop
    | odd_succ : ∀ n, even n → odd (n + 1)

end hide791

/-In this example, two types are defined simultaneously: a natural number `n` is 
  `even` if it is `0` or one more than an `odd` number, and 
  `odd` if it is one more than an `even` number. -/
  
/-Under the hood, this definition is compiled down to a single inductive type 
  with an index `i` in a two-valued type (such as `bool`), where `i` encodes 
  which of `even` or `odd` is intended. In the exercises below, you are asked 
  to spell out the details. -/

--A mutual inductive definition can also be used to define the notation of a 
--finite tree with nodes labeled by elements of `α`:

namespace hide792
  universe u

  mutual inductive tree, list_tree (α : Type u) with tree : Type u
  | node   : α → list_tree → tree with list_tree : Type u
  | nil {} : list_tree
  | cons   : tree → list_tree → list_tree

end hide792

/-With this definition, one can construct an element of `tree α` by giving an 
  element of `α` together with a list of subtrees, possibly empty. The list of 
  subtrees is represented by the type `list_tree α`, which is defined to be either 
  the empty list, `nil`, or the `cons` of a tree and an element of `list_tree α`. -/

/-This definition is inconvenient to work with, however. It would be nicer if the 
  list of subtrees were given by the type `list (tree α)`, especially since Lean's 
  library contains a number of functions and theorems for working with lists. 
  One can show that the type `list_tree α` is *isomorphic* to `list (tree α)`, 
  but translating results back and forth along this isomorphism is tedious. -/

-- In fact, Lean allows us to define the inductive type we really want:
namespace hide793
  universe u

  inductive tree (α : Type u)
  | mk : α → list tree → tree

 end hide793

/-This is known as a *nested* inductive type. It falls outside the strict 
  specification of an inductive type given in the last section because `tree` 
  does not occur strictly positively among the arguments to `mk`, but, rather, 
  nested inside the `list` type constructor. -/
  
/-Under the hood, Lean compiles this down to the mutual inductive type described 
  above, which is compiled down to an ordinary inductive type. Lean then builds 
  the isomorphism between `list_tree α` and `list (tree  α)`, and defines the 
  constructors for `tree` in terms of the isomorphism. The types of the constructors 
  for mutual and nested inductive types can be read off from the definitions. -/
  
/-Defining functions *from* such types is more complicated, because these also have 
  to be compiled down to more basic operations, making use of the primitive recursors 
  that are associated to the inductive types that are declared under the hood. Lean 
  does its best to hide the details from users, allowing them to use the equation 
  compiler, described in the next section, to define such functions in natural ways. -/

#print "==========================================="
#print "Section 7.10. Exercises"
#print " "

-- 1. Try defining other operations on the natural numbers, such as multiplication, 
--    predecessor (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` 
--    when `m` is greater than or equal to `n`), and exponentiation. 
--    Then prove some of their properties, building on the thms we already proved.
namespace hidden
  open hidden.nat 
  def mult (m n: nat): nat:= 
    nat.rec_on n zero              -- if n = zero, return 0 otherwise, given n and the 
    (λ n mult_m_n, add mult_m_n m) -- result (mult_m_n := mult m n), return mult_m_n + m

  theorem mult_zero (m : nat) : mult m zero = zero := rfl

  theorem mult_succ (m n : nat) : mult m (succ n) = add (mult m n) m := rfl

  theorem zero_mult (n : nat) : mult zero n = zero := nat.rec_on n rfl
    (assume n,
    assume ih: mult zero n = zero, show mult zero (succ n) = zero, from
      calc mult zero (succ n) = add (mult zero n) zero : mult_succ zero n
                          ... = add zero zero : ih
                          ... = zero : hidden.nat.add_zero zero)

  theorem add_succ (m n : nat) : add m (succ n) = succ (add m n) := rfl

  theorem succ_mult (n m : nat) : add (mult n m) m = mult (succ n) m := nat.rec_on m 
  (show add (mult n zero) zero = mult (succ n) zero, from 
    calc add (mult n zero) zero = add zero zero : mult_zero n
                            ... = zero : add_zero zero
                            ... = mult (succ n) zero: mult_zero (succ n))
  (assume m,
    assume ih: add (mult n m) m = mult (succ n) m, 
    show add (mult n (succ m)) (succ m) = mult (succ n) (succ m), from
    calc add (mult n (succ m)) (succ m) = add (add (mult n m) n) (succ m) : rfl
                                    ... = succ (add (add (mult n m) n) m) : by simp [add_succ]
                                    ... = succ (add (mult n m) (add n m)) : by simp [hidden.nat.add_assoc]
                                    ... = succ (add (mult n m) (add m n))  : by simp [hidden.nat.add_comm]
                                    ... = succ (add (add (mult n m) m) n): by simp [hidden.nat.add_assoc]
                                    ... = add (add (mult n m) m) (succ n) : by simp [add_succ]
                                    ... = add (mult (succ n) m) (succ n) : by simp [ih]
                                    ... = mult (succ n) (succ m) : mult_succ (succ n) m)

  theorem mult_add_distr (m n k : nat) : mult m (add n k) = add (mult m n) (mult m k) :=
    nat.rec_on k rfl
    (λ k ih, by simp [add_succ, hidden.nat.add_assoc, mult_succ, ih])

  theorem mult_assoc (m n k : nat) : mult (mult m n) k = mult m (mult n k) := 
    nat.rec_on k rfl
    (λ k ih, by simp [mult_add_distr, mult_succ, ih]) 

  theorem mult_comm (m n : nat) : mult m n = mult n m := nat.rec_on n 
        (show mult m zero = mult zero m, by simp [mult_zero, zero_mult])
        (assume n, assume ih: mult m n = mult n m,
          show mult m (succ n)= mult (succ n) m, from
          calc mult m (succ n) = add (mult m n) m : rfl
                           ... = add (mult n m) m : congr_arg (λ x, add x m) ih
                           ... = mult (succ n) m : succ_mult n m)

end hidden

-- 2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

namespace hidden

  open hidden.nat
  open hidden.list
  variables α β : Type

    lemma len_nil {α: Type} : length (nil: list α) = 0 := rfl
    lemma z_add (n : nat) : n = 0 + n :=
    begin
      induction n with n ih,
      refl,
      have h1 : succ (0 + n) = 0 + succ n, from rfl,
      have h2 : succ n = succ (0 + n), from congr_arg succ ih,
      exact eq.trans h2 h1
    end

  lemma len_cons {α : Type} (a : α) (s : list α) : length (a :: s) = succ (length s) := rfl

  theorem add_suc (m n : nat) : m + (succ n) = succ (m + n) := rfl
  theorem add_zer (n : nat) : n + 0 = n := rfl
  theorem suc_add (m n : nat) : (succ m) + n = succ (m + n) :=
  begin
    induction n,
    case zero : { refl },
    case succ : _ ih { simp [add_suc, ih] }
  end


-- a. `length (s ++ t) = length s + length t` 
  theorem length_homomorphic (s t : list α) : 
    length (s ++ t) =  (length s) + (length t) := 
    begin
      induction s,
      case nil : { rw [nil_append t, len_nil], exact z_add (length t)},
      case cons : _ _ ih { simp [cons_append,len_cons,suc_add,ih] }
    end

 --   b. `length (reverse t) = length t`
  def reverse {α : Type} : list α → list α 
  | nil := nil
  | (x::xs) := (reverse xs) ++ (x::nil)

  #reduce (cons 0 (cons 1 (cons 2 nil)))
  #reduce 0::1::2::nil                            -- {0,1,2}
  #reduce reverse (cons 0 (cons 1 (cons 2 nil)))  -- {2,1,0}

  theorem len_rev_eq_len (t: list α) : length (reverse t) = length t := 
  begin
    induction t,
    case nil : {refl},
    case cons : a t ih {
      have h : reverse (a :: t) = (reverse t) ++ (a :: nil), by refl,
      simp [h,length_homomorphic,ih,len_cons],
      rw [len_nil,add_suc,add_zer]
    }
  end   

  theorem nil_append (t : list α) : nil ++ t = t := rfl
  theorem cons_append (x : α) (s t : list α) : (x :: s) ++ t = x :: (s ++ t) := rfl
  --theorem append_associative (r s t : list α) : r ++ s ++ t = r ++ (s ++ t) := list.rec_on r

   --c. `reverse (reverse t) = t`
  lemma reverse_swapomorph (s t: list α) : reverse (s ++ t) = (reverse t) ++ (reverse s) := 
  begin induction s,
    case nil : { 
      have h0 : reverse nil = nil, refl,
      rw [nil_append,h0,append_nil],
    },
    case cons : a s ih {
      have hs : reverse (a :: s) = (reverse s) ++ (a :: nil), by refl,
      have hst : reverse (a :: (s ++ t)) = reverse (s ++ t) ++ (a :: nil), by refl,
      rw [hs, cons_append, hst, ih, append_assoc]
    } 
  end 

  theorem reverse_is_an_involution (t : list α) : reverse (reverse t) = t := 
  begin induction t,
    case nil : { refl },
    case cons : a t ih {
      have ht : reverse (a :: t) = (reverse t) ++ (a :: nil), by refl,
      have ha : reverse {a} = {a}, by refl,
      rw [ht,reverse_swapomorph,ih,ha], refl
    }
  end

-- 3. Define an inductive data type consisting of terms built from the following constructors:

      --   -  `const n`, a constant denoting the natural number `n`
      --   -  `var n`, a variable, numbered `n`
      --   -  `plus s t`, denoting the sum of `s` and `t`
      --   -  `times s t`, denoting the product of `s` and `t`
  inductive expr : Type
  | const : ℕ → expr
  | var : ℕ → expr
  | plus : expr → expr → expr
  | times : expr → expr → expr

  #check expr.const 0
  #check expr.var 1

  -- Recursively define a function that evaluates any such term with respect to an 
  -- assignment of values to the variables.
  open hidden.expr
  def eval : expr → (ℕ → ℕ) → ℕ 
  | (const n) (env: ℕ → ℕ) := n
  | (var n) (env: ℕ → ℕ) := env n
  | (plus e1 e2) env := (eval e1 env) + (eval e2 env)
  | (times e1 e2) env := (eval e1 env) * (eval e2 env)

  -- Here's an example with an environment that sets all vars to 2
  #reduce eval (times (plus (var 3) (const 5)) (var 2)) (λ n, 2)  -- result: 14

-- 4. Similarly, define the type of propositional formulas, as well as functions on 
--    the type of such formulas: an evaluation function, functions that measure the 
--    complexity of a formula, and a function that substitutes another formula for 
--    a given variable.

  inductive wff : Type
  | const : bool → wff
  | var : ℕ → wff
  | and : wff → wff → wff
  | or : wff → wff → wff
  | not : wff → wff

  --open hidden.wff

  def peval : wff → (ℕ → bool) → bool 
  | (wff.const b) (env: ℕ → bool) := b
  | (wff.var n) (env: ℕ → bool) := env n
  | (wff.and e1 e2) (env: ℕ → bool) := if (peval e1 env) then (peval e2 env) else false
  | (wff.or e1 e2) (env: ℕ → bool) := if (peval e1 env) then true else (peval e2 env)
  | (wff.not e) (env: ℕ → bool) := if (peval e env) then false else true
 

-- 5. Simulate the mutual inductive definition of `even` and `odd` described in this 
--    chapter with an ordinary inductive type, using an index to encode the choice 
--    between them in the target type.


end hidden


-- (A, {f})   If θ ⊂ A × A  is an equivalence relation on A, then
-- (∀(a, b) ( (a, b) ∈ θ  →  (f(a), f(b)) ∈ θ )  ⇒  θ ∈ Con (A)
